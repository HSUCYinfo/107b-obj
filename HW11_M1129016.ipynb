{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNLGWnZ0sKjeNadX5lw3kUS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"mZiU3XAuuJEC","executionInfo":{"status":"ok","timestamp":1670373809686,"user_tz":-480,"elapsed":546,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}}},"outputs":[],"source":["import string\n","\n","class Vectorizer:\n","    def standardize(self, text):\n","        text = text.lower()\n","        return \"\".join(char for char in text if char not in string.punctuation)\n","\n","    def tokenize(self, text):\n","        text = self.standardize(text)\n","        return text.split()\n","\n","    def make_vocabulary(self, dataset):\n","        self.vocabulary = {\"\": 0, \"[UNK]\": 1}\n","        for text in dataset:\n","            text = self.standardize(text)\n","            tokens = self.tokenize(text)\n","            for token in tokens:\n","                if token not in self.vocabulary:\n","                    self.vocabulary[token] = len(self.vocabulary)\n","        self.inverse_vocabulary = dict(\n","            (v, k) for k, v in self.vocabulary.items())\n","\n","    def encode(self, text):\n","        text = self.standardize(text)\n","        tokens = self.tokenize(text)\n","        return [self.vocabulary.get(token, 1) for token in tokens]\n","\n","    def decode(self, int_sequence):\n","        return \" \".join(\n","            self.inverse_vocabulary.get(i, \"[UNK]\") for i in int_sequence)\n","\n","vectorizer = Vectorizer()\n","dataset = [\n","    \"I write, erase, rewrite\",\n","    \"Erase again, and then\",\n","    \"A poppy blooms.\",\n","]\n","vectorizer.make_vocabulary(dataset)"]},{"cell_type":"code","source":["test_sentence = \"I write, rewrite, and still rewrite again\"\n","encoded_sentence = vectorizer.encode(test_sentence)\n","print(encoded_sentence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uAwXwrZiCanS","executionInfo":{"status":"ok","timestamp":1670373818167,"user_tz":-480,"elapsed":4,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}},"outputId":"9e24beb2-5684-45ec-bc9d-29c6941cf7e8"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["[2, 3, 5, 7, 1, 5, 6]\n"]}]},{"cell_type":"code","source":["decoded_sentence = vectorizer.decode(encoded_sentence)\n","print(decoded_sentence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1GqChrKTCdZB","executionInfo":{"status":"ok","timestamp":1670373827353,"user_tz":-480,"elapsed":451,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}},"outputId":"32cb5830-e207-42f2-97a4-3cae1129f2b7"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["i write rewrite and [UNK] rewrite again\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.layers import TextVectorization\n","text_vectorization = TextVectorization(\n","    output_mode=\"int\",\n",")"],"metadata":{"id":"PR2u1O-pCe96","executionInfo":{"status":"ok","timestamp":1670373837941,"user_tz":-480,"elapsed":5448,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import re\n","import string\n","import tensorflow as tf\n","\n","def custom_standardization_fn(string_tensor):\n","    lowercase_string = tf.strings.lower(string_tensor)\n","    return tf.strings.regex_replace(\n","        lowercase_string, f\"[{re.escape(string.punctuation)}]\", \"\")\n","\n","def custom_split_fn(string_tensor):\n","    return tf.strings.split(string_tensor)\n","\n","text_vectorization = TextVectorization(\n","    output_mode=\"int\",\n","    standardize=custom_standardization_fn,\n","    split=custom_split_fn,\n",")"],"metadata":{"id":"QOX4BWJBCg6x","executionInfo":{"status":"ok","timestamp":1670373840637,"user_tz":-480,"elapsed":362,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["dataset = [\n","    \"I write, erase, rewrite\",\n","    \"Erase again, and then\",\n","    \"A poppy blooms.\",\n","]\n","text_vectorization.adapt(dataset)"],"metadata":{"id":"5IdrDXDlCiix","executionInfo":{"status":"ok","timestamp":1670373847725,"user_tz":-480,"elapsed":1163,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["text_vectorization.get_vocabulary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PBWE3y3GCj2B","executionInfo":{"status":"ok","timestamp":1670373853077,"user_tz":-480,"elapsed":539,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}},"outputId":"a6f87a3a-452f-4a90-f855-cbe4d2600110"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['',\n"," '[UNK]',\n"," 'erase',\n"," 'write',\n"," 'then',\n"," 'rewrite',\n"," 'poppy',\n"," 'i',\n"," 'blooms',\n"," 'and',\n"," 'again',\n"," 'a']"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["vocabulary = text_vectorization.get_vocabulary()\n","test_sentence = \"I write, rewrite, and still rewrite again\"\n","encoded_sentence = text_vectorization(test_sentence)\n","print(encoded_sentence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7DKymeWfClXx","executionInfo":{"status":"ok","timestamp":1670373858864,"user_tz":-480,"elapsed":337,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}},"outputId":"1406c5ce-110d-4cf4-a152-a0c46d5a3361"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor([ 7  3  5  9  1  5 10], shape=(7,), dtype=int64)\n"]}]},{"cell_type":"code","source":["inverse_vocab = dict(enumerate(vocabulary))\n","decoded_sentence = \" \".join(inverse_vocab[int(i)] for i in encoded_sentence)\n","print(decoded_sentence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W0ga2OOtCm57","executionInfo":{"status":"ok","timestamp":1670373864959,"user_tz":-480,"elapsed":458,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}},"outputId":"5eedab6b-3d37-43dc-dee9-051aa386ed0e"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["i write rewrite and [UNK] rewrite again\n"]}]},{"cell_type":"code","source":["!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n","!tar -xf aclImdb_v1.tar.gz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vcqedHrGCoea","executionInfo":{"status":"ok","timestamp":1670373885738,"user_tz":-480,"elapsed":14747,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}},"outputId":"3a126e17-e829-4f0f-b95d-7194b6b8b8e6"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100 80.2M  100 80.2M    0     0  10.0M      0  0:00:08  0:00:08 --:--:-- 18.0M\n"]}]},{"cell_type":"code","source":["!rm -r aclImdb/train/unsup"],"metadata":{"id":"ANTIX2JBCuPQ","executionInfo":{"status":"ok","timestamp":1670373901469,"user_tz":-480,"elapsed":1354,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["!cat aclImdb/train/pos/4077_10.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WIbfKXRxCwxQ","executionInfo":{"status":"ok","timestamp":1670373907007,"user_tz":-480,"elapsed":5,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}},"outputId":"83cff4b8-6a39-4ef8-a52a-317d83c14861"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["I first saw this back in the early 90s on UK TV, i did like it then but i missed the chance to tape it, many years passed but the film always stuck with me and i lost hope of seeing it TV again, the main thing that stuck with me was the end, the hole castle part really touched me, its easy to watch, has a great story, great music, the list goes on and on, its OK me saying how good it is but everyone will take there own best bits away with them once they have seen it, yes the animation is top notch and beautiful to watch, it does show its age in a very few parts but that has now become part of it beauty, i am so glad it has came out on DVD as it is one of my top 10 films of all time. Buy it or rent it just see it, best viewing is at night alone with drink and food in reach so you don't have to stop the film.<br /><br />Enjoy"]}]},{"cell_type":"code","source":["import os, pathlib, shutil, random\n","\n","base_dir = pathlib.Path(\"aclImdb\")\n","val_dir = base_dir / \"val\"\n","train_dir = base_dir / \"train\"\n","for category in (\"neg\", \"pos\"):\n","    os.makedirs(val_dir / category)\n","    files = os.listdir(train_dir / category)\n","    random.Random(1337).shuffle(files)\n","    num_val_samples = int(0.2 * len(files))\n","    val_files = files[-num_val_samples:]\n","    for fname in val_files:\n","        shutil.move(train_dir / category / fname,\n","                    val_dir / category / fname)"],"metadata":{"id":"6xUtwED2CypY","executionInfo":{"status":"ok","timestamp":1670373915471,"user_tz":-480,"elapsed":2,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["from tensorflow import keras\n","batch_size = 32\n","\n","train_ds = keras.utils.text_dataset_from_directory(\n","    \"aclImdb/train\", batch_size=batch_size\n",")\n","val_ds = keras.utils.text_dataset_from_directory(\n","    \"aclImdb/val\", batch_size=batch_size\n",")\n","test_ds = keras.utils.text_dataset_from_directory(\n","    \"aclImdb/test\", batch_size=batch_size\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"08hHik_pC0sQ","executionInfo":{"status":"ok","timestamp":1670373924921,"user_tz":-480,"elapsed":3329,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}},"outputId":"53f8e9df-8c54-46a7-d949-926a91f8a1dd"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 20000 files belonging to 2 classes.\n","Found 5000 files belonging to 2 classes.\n","Found 25000 files belonging to 2 classes.\n"]}]},{"cell_type":"code","source":["for inputs, targets in train_ds:\n","    print(\"inputs.shape:\", inputs.shape)\n","    print(\"inputs.dtype:\", inputs.dtype)\n","    print(\"targets.shape:\", targets.shape)\n","    print(\"targets.dtype:\", targets.dtype)\n","    print(\"inputs[0]:\", inputs[0])\n","    print(\"targets[0]:\", targets[0])\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yjg25FmqC2d5","executionInfo":{"status":"ok","timestamp":1670373929191,"user_tz":-480,"elapsed":6,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}},"outputId":"cda06cf9-dd7c-4c21-8210-92020c808477"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["inputs.shape: (32,)\n","inputs.dtype: <dtype: 'string'>\n","targets.shape: (32,)\n","targets.dtype: <dtype: 'int32'>\n","inputs[0]: tf.Tensor(b\"I had the pleasure of viewing this movie early and I have to say I thought that it was going to be boring and wondered how could they ever improve upon the 1984 version of Bachelor Party starring Tom Hanks, which I thought was pretty good...I was right...In all honesty I thought it could have been better...Sure there were some funny moments but it just didn't seem to hit the mark with me...The acting was OK and the storyline pretty well follows the original but I think it could have been so much better...This movie I'd say is for teens and the young of heart; full of female bodies, alcohol and sex...It's just another typical run of the mill party movie that has been done over and over again. 4/10 is my vote for this one.\", shape=(), dtype=string)\n","targets[0]: tf.Tensor(0, shape=(), dtype=int32)\n"]}]},{"cell_type":"code","source":["text_vectorization = TextVectorization(\n","    max_tokens=20000,\n","    output_mode=\"multi_hot\",\n",")\n","text_only_train_ds = train_ds.map(lambda x, y: x)\n","text_vectorization.adapt(text_only_train_ds)\n","\n","binary_1gram_train_ds = train_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","binary_1gram_val_ds = val_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","binary_1gram_test_ds = test_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)"],"metadata":{"id":"nfQk1L7kC4Wp","executionInfo":{"status":"ok","timestamp":1670373943343,"user_tz":-480,"elapsed":6332,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["for inputs, targets in binary_1gram_train_ds:\n","    print(\"inputs.shape:\", inputs.shape)\n","    print(\"inputs.dtype:\", inputs.dtype)\n","    print(\"targets.shape:\", targets.shape)\n","    print(\"targets.dtype:\", targets.dtype)\n","    print(\"inputs[0]:\", inputs[0])\n","    print(\"targets[0]:\", targets[0])\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eiIExq8gC-NY","executionInfo":{"status":"ok","timestamp":1670373961961,"user_tz":-480,"elapsed":3,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}},"outputId":"79201849-9169-4d34-ba12-10f5e75c145d"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["inputs.shape: (32, 20000)\n","inputs.dtype: <dtype: 'float32'>\n","targets.shape: (32,)\n","targets.dtype: <dtype: 'int32'>\n","inputs[0]: tf.Tensor([1. 1. 1. ... 0. 0. 0.], shape=(20000,), dtype=float32)\n","targets[0]: tf.Tensor(0, shape=(), dtype=int32)\n"]}]},{"cell_type":"code","source":["from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","def get_model(max_tokens=20000, hidden_dim=16):\n","    inputs = keras.Input(shape=(max_tokens,))\n","    x = layers.Dense(hidden_dim, activation=\"relu\")(inputs)\n","    x = layers.Dropout(0.5)(x)\n","    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","    model = keras.Model(inputs, outputs)\n","    model.compile(optimizer=\"rmsprop\",\n","                  loss=\"binary_crossentropy\",\n","                  metrics=[\"accuracy\"])\n","    return model"],"metadata":{"id":"z-22HAIoDASi","executionInfo":{"status":"ok","timestamp":1670373969563,"user_tz":-480,"elapsed":339,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["model = get_model()\n","model.summary()\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint(\"binary_1gram.keras\",\n","                                    save_best_only=True)\n","]\n","model.fit(binary_1gram_train_ds.cache(),\n","          validation_data=binary_1gram_val_ds.cache(),\n","          epochs=10,\n","          callbacks=callbacks)\n","model = keras.models.load_model(\"binary_1gram.keras\")\n","print(f\"Test acc: {model.evaluate(binary_1gram_test_ds)[1]:.3f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RO7aW4k2DCvw","executionInfo":{"status":"ok","timestamp":1670374031534,"user_tz":-480,"elapsed":51268,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}},"outputId":"02aa837d-6159-40d3-b44f-7b000f517cd5"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 20000)]           0         \n","                                                                 \n"," dense (Dense)               (None, 16)                320016    \n","                                                                 \n"," dropout (Dropout)           (None, 16)                0         \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 17        \n","                                                                 \n","=================================================================\n","Total params: 320,033\n","Trainable params: 320,033\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","625/625 [==============================] - 11s 14ms/step - loss: 0.4163 - accuracy: 0.8236 - val_loss: 0.2953 - val_accuracy: 0.8836\n","Epoch 2/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.2756 - accuracy: 0.8999 - val_loss: 0.2915 - val_accuracy: 0.8848\n","Epoch 3/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.2493 - accuracy: 0.9118 - val_loss: 0.3077 - val_accuracy: 0.8860\n","Epoch 4/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.2311 - accuracy: 0.9204 - val_loss: 0.3263 - val_accuracy: 0.8868\n","Epoch 5/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.2291 - accuracy: 0.9250 - val_loss: 0.3423 - val_accuracy: 0.8838\n","Epoch 6/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.2221 - accuracy: 0.9280 - val_loss: 0.3462 - val_accuracy: 0.8812\n","Epoch 7/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.2121 - accuracy: 0.9323 - val_loss: 0.3630 - val_accuracy: 0.8806\n","Epoch 8/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.2134 - accuracy: 0.9329 - val_loss: 0.3724 - val_accuracy: 0.8818\n","Epoch 9/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.2073 - accuracy: 0.9340 - val_loss: 0.3895 - val_accuracy: 0.8758\n","Epoch 10/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.2058 - accuracy: 0.9354 - val_loss: 0.3812 - val_accuracy: 0.8874\n","782/782 [==============================] - 8s 9ms/step - loss: 0.2853 - accuracy: 0.8886\n","Test acc: 0.889\n"]}]},{"cell_type":"code","source":["text_vectorization = TextVectorization(\n","    ngrams=2,\n","    max_tokens=20000,\n","    output_mode=\"multi_hot\",\n",")"],"metadata":{"id":"-r_Kd0PrDiE5","executionInfo":{"status":"ok","timestamp":1670374113034,"user_tz":-480,"elapsed":2,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["text_vectorization.adapt(text_only_train_ds)\n","binary_2gram_train_ds = train_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","binary_2gram_val_ds = val_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","binary_2gram_test_ds = test_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","\n","model = get_model()\n","model.summary()\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint(\"binary_2gram.keras\",\n","                                    save_best_only=True)\n","]\n","model.fit(binary_2gram_train_ds.cache(),\n","          validation_data=binary_2gram_val_ds.cache(),\n","          epochs=10,\n","          callbacks=callbacks)\n","model = keras.models.load_model(\"binary_2gram.keras\")\n","print(f\"Test acc: {model.evaluate(binary_2gram_test_ds)[1]:.3f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L51cU8yqDk-4","executionInfo":{"status":"ok","timestamp":1670374190249,"user_tz":-480,"elapsed":70439,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}},"outputId":"c2fc4532-dc71-455d-b182-125310fee854"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 20000)]           0         \n","                                                                 \n"," dense_2 (Dense)             (None, 16)                320016    \n","                                                                 \n"," dropout_1 (Dropout)         (None, 16)                0         \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 17        \n","                                                                 \n","=================================================================\n","Total params: 320,033\n","Trainable params: 320,033\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","625/625 [==============================] - 10s 15ms/step - loss: 0.3710 - accuracy: 0.8479 - val_loss: 0.2819 - val_accuracy: 0.8884\n","Epoch 2/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.2347 - accuracy: 0.9181 - val_loss: 0.2820 - val_accuracy: 0.8988\n","Epoch 3/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.2047 - accuracy: 0.9342 - val_loss: 0.3037 - val_accuracy: 0.8960\n","Epoch 4/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.1889 - accuracy: 0.9414 - val_loss: 0.3239 - val_accuracy: 0.8954\n","Epoch 5/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.1826 - accuracy: 0.9463 - val_loss: 0.3362 - val_accuracy: 0.8956\n","Epoch 6/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.1705 - accuracy: 0.9495 - val_loss: 0.3573 - val_accuracy: 0.8960\n","Epoch 7/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.1688 - accuracy: 0.9510 - val_loss: 0.3747 - val_accuracy: 0.8956\n","Epoch 8/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.1720 - accuracy: 0.9530 - val_loss: 0.3991 - val_accuracy: 0.8930\n","Epoch 9/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.1705 - accuracy: 0.9549 - val_loss: 0.3920 - val_accuracy: 0.8890\n","Epoch 10/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.1673 - accuracy: 0.9549 - val_loss: 0.4020 - val_accuracy: 0.8908\n","782/782 [==============================] - 8s 10ms/step - loss: 0.2719 - accuracy: 0.8970\n","Test acc: 0.897\n"]}]},{"cell_type":"code","source":["text_vectorization = TextVectorization(\n","    ngrams=2,\n","    max_tokens=20000,\n","    output_mode=\"count\"\n",")"],"metadata":{"id":"S8sgtDKjEV4A","executionInfo":{"status":"ok","timestamp":1670374339094,"user_tz":-480,"elapsed":343,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["text_vectorization = TextVectorization(\n","    ngrams=2,\n","    max_tokens=20000,\n","    output_mode=\"tf_idf\",\n",")"],"metadata":{"id":"m5SylYWIEb20","executionInfo":{"status":"ok","timestamp":1670374345224,"user_tz":-480,"elapsed":3,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["text_vectorization.adapt(text_only_train_ds)\n","\n","tfidf_2gram_train_ds = train_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","tfidf_2gram_val_ds = val_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","tfidf_2gram_test_ds = test_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","\n","model = get_model()\n","model.summary()\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint(\"tfidf_2gram.keras\",\n","                                    save_best_only=True)\n","]\n","model.fit(tfidf_2gram_train_ds.cache(),\n","          validation_data=tfidf_2gram_val_ds.cache(),\n","          epochs=10,\n","          callbacks=callbacks)\n","model = keras.models.load_model(\"tfidf_2gram.keras\")\n","print(f\"Test acc: {model.evaluate(tfidf_2gram_test_ds)[1]:.3f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HxPtuE8aEdyY","executionInfo":{"status":"ok","timestamp":1670374426523,"user_tz":-480,"elapsed":73475,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}},"outputId":"16bb7ad6-0ed4-4bd5-822c-7dfbf89d582d"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_3 (InputLayer)        [(None, 20000)]           0         \n","                                                                 \n"," dense_4 (Dense)             (None, 16)                320016    \n","                                                                 \n"," dropout_2 (Dropout)         (None, 16)                0         \n","                                                                 \n"," dense_5 (Dense)             (None, 1)                 17        \n","                                                                 \n","=================================================================\n","Total params: 320,033\n","Trainable params: 320,033\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","625/625 [==============================] - 10s 16ms/step - loss: 0.5259 - accuracy: 0.7204 - val_loss: 0.3395 - val_accuracy: 0.8670\n","Epoch 2/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.4030 - accuracy: 0.8051 - val_loss: 0.3263 - val_accuracy: 0.8762\n","Epoch 3/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.3593 - accuracy: 0.8210 - val_loss: 0.3527 - val_accuracy: 0.8330\n","Epoch 4/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.3443 - accuracy: 0.8397 - val_loss: 0.3386 - val_accuracy: 0.8792\n","Epoch 5/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.3273 - accuracy: 0.8479 - val_loss: 0.3735 - val_accuracy: 0.8322\n","Epoch 6/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.3077 - accuracy: 0.8580 - val_loss: 0.3682 - val_accuracy: 0.8542\n","Epoch 7/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.3030 - accuracy: 0.8616 - val_loss: 0.3679 - val_accuracy: 0.8560\n","Epoch 8/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.2925 - accuracy: 0.8638 - val_loss: 0.3584 - val_accuracy: 0.8586\n","Epoch 9/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.2895 - accuracy: 0.8623 - val_loss: 0.3631 - val_accuracy: 0.8560\n","Epoch 10/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.2863 - accuracy: 0.8662 - val_loss: 0.3669 - val_accuracy: 0.8596\n","782/782 [==============================] - 9s 11ms/step - loss: 0.3218 - accuracy: 0.8782\n","Test acc: 0.878\n"]}]},{"cell_type":"code","source":["inputs = keras.Input(shape=(1,), dtype=\"string\")\n","processed_inputs = text_vectorization(inputs)\n","outputs = model(processed_inputs)\n","inference_model = keras.Model(inputs, outputs)"],"metadata":{"id":"EXWIqMmvEw-H","executionInfo":{"status":"ok","timestamp":1670374437628,"user_tz":-480,"elapsed":3,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","raw_text_data = tf.convert_to_tensor([\n","    [\"That was an excellent movie, I loved it.\"],\n","])\n","predictions = inference_model(raw_text_data)\n","print(f\"{float(predictions[0] * 100):.2f} percent positive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wZfHTUdnE0Dw","executionInfo":{"status":"ok","timestamp":1670374444539,"user_tz":-480,"elapsed":2,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}},"outputId":"dd9a1925-9c38-4060-8f4c-5bb31678abc6"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["94.07 percent positive\n"]}]},{"cell_type":"code","source":["!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n","!tar -xf aclImdb_v1.tar.gz\n","!rm -r aclImdb/train/unsup"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9VJuTrRME1_H","executionInfo":{"status":"ok","timestamp":1670374467765,"user_tz":-480,"elapsed":16850,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}},"outputId":"8dc1266f-1a66-4eb2-b7d0-f7fe4184434a"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100 80.2M  100 80.2M    0     0  10.3M      0  0:00:07  0:00:07 --:--:-- 16.6M\n"]}]},{"cell_type":"code","source":["from tensorflow.keras import layers\n","\n","max_length = 600\n","max_tokens = 20000\n","text_vectorization = layers.TextVectorization(\n","    max_tokens=max_tokens,\n","    output_mode=\"int\",\n","    output_sequence_length=max_length,\n",")\n","text_vectorization.adapt(text_only_train_ds)\n","\n","int_train_ds = train_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","int_val_ds = val_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","int_test_ds = test_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)"],"metadata":{"id":"-EZ8HUyRFAfR","executionInfo":{"status":"ok","timestamp":1670374500278,"user_tz":-480,"elapsed":5108,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","inputs = keras.Input(shape=(None,), dtype=\"int64\")\n","embedded = tf.one_hot(inputs, depth=max_tokens)\n","x = layers.Bidirectional(layers.LSTM(32))(embedded)\n","x = layers.Dropout(0.5)(x)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model = keras.Model(inputs, outputs)\n","model.compile(optimizer=\"rmsprop\",\n","              loss=\"binary_crossentropy\",\n","              metrics=[\"accuracy\"])\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S9Dyj7RoFCz_","executionInfo":{"status":"ok","timestamp":1670374505204,"user_tz":-480,"elapsed":552,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}},"outputId":"b5e888ce-6155-40bd-ae2f-94f0dce985a4"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_5 (InputLayer)        [(None, None)]            0         \n","                                                                 \n"," tf.one_hot (TFOpLambda)     (None, None, 20000)       0         \n","                                                                 \n"," bidirectional (Bidirectiona  (None, 64)               5128448   \n"," l)                                                              \n","                                                                 \n"," dropout_3 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_6 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 5,128,513\n","Trainable params: 5,128,513\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["callbacks = [\n","    keras.callbacks.ModelCheckpoint(\"one_hot_bidir_lstm.keras\",\n","                                    save_best_only=True)\n","]\n","model.fit(int_train_ds, validation_data=int_val_ds, epochs=2, callbacks=callbacks)\n","model = keras.models.load_model(\"one_hot_bidir_lstm.keras\")\n","print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hPAwbHjtFZOA","executionInfo":{"status":"ok","timestamp":1670375081152,"user_tz":-480,"elapsed":477572,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}},"outputId":"21cd0ae9-c3e7-4b14-a2d6-8fdbc5a572d6"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","625/625 [==============================] - 172s 261ms/step - loss: 0.5356 - accuracy: 0.7525 - val_loss: 0.3862 - val_accuracy: 0.8592\n","Epoch 2/2\n","625/625 [==============================] - 168s 268ms/step - loss: 0.3471 - accuracy: 0.8766 - val_loss: 0.3487 - val_accuracy: 0.8698\n","782/782 [==============================] - 103s 131ms/step - loss: 0.3469 - accuracy: 0.8672\n","Test acc: 0.867\n"]}]},{"cell_type":"code","source":["embedding_layer = layers.Embedding(input_dim=max_tokens, output_dim=256)"],"metadata":{"id":"f1Vqbf1nHvIY","executionInfo":{"status":"ok","timestamp":1670375211674,"user_tz":-480,"elapsed":362,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["inputs = keras.Input(shape=(None,), dtype=\"int64\")\n","embedded = layers.Embedding(input_dim=max_tokens, output_dim=256)(inputs)\n","x = layers.Bidirectional(layers.LSTM(32))(embedded)\n","x = layers.Dropout(0.5)(x)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model = keras.Model(inputs, outputs)\n","model.compile(optimizer=\"rmsprop\",\n","              loss=\"binary_crossentropy\",\n","              metrics=[\"accuracy\"])\n","model.summary()\n","\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint(\"embeddings_bidir_gru.keras\",\n","                                    save_best_only=True)\n","]\n","model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callbacks)\n","model = keras.models.load_model(\"embeddings_bidir_gru.keras\")\n","print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3UBw3ypJHxQR","executionInfo":{"status":"ok","timestamp":1670375648151,"user_tz":-480,"elapsed":429159,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}},"outputId":"b9747c45-f9ce-42c5-8095-2f425cfce679"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_5\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_6 (InputLayer)        [(None, None)]            0         \n","                                                                 \n"," embedding_1 (Embedding)     (None, None, 256)         5120000   \n","                                                                 \n"," bidirectional_1 (Bidirectio  (None, 64)               73984     \n"," nal)                                                            \n","                                                                 \n"," dropout_4 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_7 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 5,194,049\n","Trainable params: 5,194,049\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","625/625 [==============================] - 41s 60ms/step - loss: 0.4573 - accuracy: 0.7981 - val_loss: 0.8168 - val_accuracy: 0.7116\n","Epoch 2/10\n","625/625 [==============================] - 36s 57ms/step - loss: 0.3079 - accuracy: 0.8887 - val_loss: 0.3733 - val_accuracy: 0.8692\n","Epoch 3/10\n","625/625 [==============================] - 37s 59ms/step - loss: 0.2433 - accuracy: 0.9155 - val_loss: 0.3945 - val_accuracy: 0.8710\n","Epoch 4/10\n","625/625 [==============================] - 36s 58ms/step - loss: 0.1999 - accuracy: 0.9326 - val_loss: 0.3471 - val_accuracy: 0.8682\n","Epoch 5/10\n","625/625 [==============================] - 35s 55ms/step - loss: 0.1742 - accuracy: 0.9429 - val_loss: 0.3758 - val_accuracy: 0.8748\n","Epoch 6/10\n","625/625 [==============================] - 34s 54ms/step - loss: 0.1483 - accuracy: 0.9517 - val_loss: 0.4121 - val_accuracy: 0.8822\n","Epoch 7/10\n","625/625 [==============================] - 34s 55ms/step - loss: 0.1224 - accuracy: 0.9615 - val_loss: 0.4451 - val_accuracy: 0.8700\n","Epoch 8/10\n","625/625 [==============================] - 34s 54ms/step - loss: 0.1019 - accuracy: 0.9674 - val_loss: 0.4468 - val_accuracy: 0.8772\n","Epoch 9/10\n","625/625 [==============================] - 33s 53ms/step - loss: 0.0872 - accuracy: 0.9732 - val_loss: 0.4663 - val_accuracy: 0.8776\n","Epoch 10/10\n","625/625 [==============================] - 34s 55ms/step - loss: 0.0748 - accuracy: 0.9760 - val_loss: 0.5167 - val_accuracy: 0.8654\n","782/782 [==============================] - 22s 28ms/step - loss: 0.3835 - accuracy: 0.8541\n","Test acc: 0.854\n"]}]},{"cell_type":"code","source":["inputs = keras.Input(shape=(None,), dtype=\"int64\")\n","embedded = layers.Embedding(\n","    input_dim=max_tokens, output_dim=256, mask_zero=True)(inputs)\n","x = layers.Bidirectional(layers.LSTM(32))(embedded)\n","x = layers.Dropout(0.5)(x)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model = keras.Model(inputs, outputs)\n","model.compile(optimizer=\"rmsprop\",\n","              loss=\"binary_crossentropy\",\n","              metrics=[\"accuracy\"])\n","model.summary()\n","\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint(\"embeddings_bidir_gru_with_masking.keras\",\n","                                    save_best_only=True)\n","]\n","model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callbacks)\n","model = keras.models.load_model(\"embeddings_bidir_gru_with_masking.keras\")\n","print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-P5PApRKLJLk","executionInfo":{"status":"ok","timestamp":1670376810131,"user_tz":-480,"elapsed":693064,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}},"outputId":"c1f0975c-0b7e-4ca7-a012-c559e63e2968"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_6\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_7 (InputLayer)        [(None, None)]            0         \n","                                                                 \n"," embedding_2 (Embedding)     (None, None, 256)         5120000   \n","                                                                 \n"," bidirectional_2 (Bidirectio  (None, 64)               73984     \n"," nal)                                                            \n","                                                                 \n"," dropout_5 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_8 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 5,194,049\n","Trainable params: 5,194,049\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","625/625 [==============================] - 52s 71ms/step - loss: 0.3919 - accuracy: 0.8233 - val_loss: 0.3063 - val_accuracy: 0.8696\n","Epoch 2/10\n","625/625 [==============================] - 38s 61ms/step - loss: 0.2252 - accuracy: 0.9130 - val_loss: 0.2895 - val_accuracy: 0.8858\n","Epoch 3/10\n","625/625 [==============================] - 41s 66ms/step - loss: 0.1633 - accuracy: 0.9381 - val_loss: 0.3063 - val_accuracy: 0.8806\n","Epoch 4/10\n","625/625 [==============================] - 38s 60ms/step - loss: 0.1210 - accuracy: 0.9570 - val_loss: 0.3508 - val_accuracy: 0.8790\n","Epoch 5/10\n","625/625 [==============================] - 42s 68ms/step - loss: 0.0859 - accuracy: 0.9690 - val_loss: 0.3902 - val_accuracy: 0.8780\n","Epoch 6/10\n","625/625 [==============================] - 41s 66ms/step - loss: 0.0662 - accuracy: 0.9759 - val_loss: 0.5274 - val_accuracy: 0.8618\n","Epoch 7/10\n","625/625 [==============================] - 41s 65ms/step - loss: 0.0482 - accuracy: 0.9836 - val_loss: 0.5212 - val_accuracy: 0.8668\n","Epoch 8/10\n","625/625 [==============================] - 42s 67ms/step - loss: 0.0394 - accuracy: 0.9879 - val_loss: 0.5499 - val_accuracy: 0.8670\n","Epoch 9/10\n","625/625 [==============================] - 40s 64ms/step - loss: 0.0260 - accuracy: 0.9911 - val_loss: 0.5973 - val_accuracy: 0.8712\n","Epoch 10/10\n","625/625 [==============================] - 41s 65ms/step - loss: 0.0196 - accuracy: 0.9938 - val_loss: 0.6071 - val_accuracy: 0.8618\n","782/782 [==============================] - 25s 29ms/step - loss: 0.2925 - accuracy: 0.8840\n","Test acc: 0.884\n"]}]},{"cell_type":"code","source":["!wget http://nlp.stanford.edu/data/glove.6B.zip\n","!unzip -q glove.6B.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3qEwRSFTOCjv","executionInfo":{"status":"ok","timestamp":1670377047821,"user_tz":-480,"elapsed":183249,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}},"outputId":"b351593a-eaf1-46b0-8a09-ea6393141b47"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-12-07 01:34:24--  http://nlp.stanford.edu/data/glove.6B.zip\n","Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n","--2022-12-07 01:34:24--  https://nlp.stanford.edu/data/glove.6B.zip\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n","--2022-12-07 01:34:25--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n","Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n","Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 862182613 (822M) [application/zip]\n","Saving to: ‘glove.6B.zip’\n","\n","glove.6B.zip        100%[===================>] 822.24M  5.02MB/s    in 2m 40s  \n","\n","2022-12-07 01:37:06 (5.13 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n","\n"]}]},{"cell_type":"code","source":["import numpy as np\n","path_to_glove_file = \"glove.6B.100d.txt\"\n","\n","embeddings_index = {}\n","with open(path_to_glove_file) as f:\n","    for line in f:\n","        word, coefs = line.split(maxsplit=1)\n","        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n","        embeddings_index[word] = coefs\n","\n","print(f\"Found {len(embeddings_index)} word vectors.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o2QtgqkhQB4q","executionInfo":{"status":"ok","timestamp":1670377405605,"user_tz":-480,"elapsed":6666,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}},"outputId":"16d1e4fc-94ad-4a62-e568-ee240837bfbf"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 400000 word vectors.\n"]}]},{"cell_type":"code","source":["embedding_dim = 100\n","\n","vocabulary = text_vectorization.get_vocabulary()\n","word_index = dict(zip(vocabulary, range(len(vocabulary))))\n","\n","embedding_matrix = np.zeros((max_tokens, embedding_dim))\n","for word, i in word_index.items():\n","    if i < max_tokens:\n","        embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None:\n","        embedding_matrix[i] = embedding_vector"],"metadata":{"id":"WWgH7SrWQIYF","executionInfo":{"status":"ok","timestamp":1670377410953,"user_tz":-480,"elapsed":2,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["embedding_layer = layers.Embedding(\n","    max_tokens,\n","    embedding_dim,\n","    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n","    trainable=False,\n","    mask_zero=True,\n",")"],"metadata":{"id":"Lnva8tihQJzM","executionInfo":{"status":"ok","timestamp":1670377415776,"user_tz":-480,"elapsed":356,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["inputs = keras.Input(shape=(None,), dtype=\"int64\")\n","embedded = embedding_layer(inputs)\n","x = layers.Bidirectional(layers.LSTM(32))(embedded)\n","x = layers.Dropout(0.5)(x)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model = keras.Model(inputs, outputs)\n","model.compile(optimizer=\"rmsprop\",\n","              loss=\"binary_crossentropy\",\n","              metrics=[\"accuracy\"])\n","model.summary()\n","\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint(\"glove_embeddings_sequence_model.keras\",\n","                                    save_best_only=True)\n","]\n","model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callbacks)\n","model = keras.models.load_model(\"glove_embeddings_sequence_model.keras\")\n","print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LDDxPMT8QLkd","executionInfo":{"status":"ok","timestamp":1670377853641,"user_tz":-480,"elapsed":428948,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}},"outputId":"738de865-814f-4004-ff05-83de72c93b5c"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_7\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_8 (InputLayer)        [(None, None)]            0         \n","                                                                 \n"," embedding_3 (Embedding)     (None, None, 100)         2000000   \n","                                                                 \n"," bidirectional_3 (Bidirectio  (None, 64)               34048     \n"," nal)                                                            \n","                                                                 \n"," dropout_6 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_9 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 2,034,113\n","Trainable params: 34,113\n","Non-trainable params: 2,000,000\n","_________________________________________________________________\n","Epoch 1/10\n","625/625 [==============================] - 43s 57ms/step - loss: 0.5716 - accuracy: 0.6992 - val_loss: 0.5071 - val_accuracy: 0.7350\n","Epoch 2/10\n","625/625 [==============================] - 35s 55ms/step - loss: 0.4571 - accuracy: 0.7919 - val_loss: 0.4170 - val_accuracy: 0.8092\n","Epoch 3/10\n","625/625 [==============================] - 34s 54ms/step - loss: 0.4059 - accuracy: 0.8187 - val_loss: 0.3818 - val_accuracy: 0.8244\n","Epoch 4/10\n","625/625 [==============================] - 34s 55ms/step - loss: 0.3682 - accuracy: 0.8388 - val_loss: 0.3629 - val_accuracy: 0.8442\n","Epoch 5/10\n","625/625 [==============================] - 34s 54ms/step - loss: 0.3461 - accuracy: 0.8507 - val_loss: 0.4328 - val_accuracy: 0.8152\n","Epoch 6/10\n","625/625 [==============================] - 34s 55ms/step - loss: 0.3268 - accuracy: 0.8627 - val_loss: 0.3236 - val_accuracy: 0.8624\n","Epoch 7/10\n","625/625 [==============================] - 33s 52ms/step - loss: 0.3046 - accuracy: 0.8725 - val_loss: 0.3820 - val_accuracy: 0.8312\n","Epoch 8/10\n","625/625 [==============================] - 34s 54ms/step - loss: 0.2915 - accuracy: 0.8802 - val_loss: 0.3158 - val_accuracy: 0.8660\n","Epoch 9/10\n","625/625 [==============================] - 34s 55ms/step - loss: 0.2759 - accuracy: 0.8879 - val_loss: 0.3088 - val_accuracy: 0.8682\n","Epoch 10/10\n","625/625 [==============================] - 34s 55ms/step - loss: 0.2629 - accuracy: 0.8938 - val_loss: 0.3317 - val_accuracy: 0.8634\n","782/782 [==============================] - 22s 25ms/step - loss: 0.3030 - accuracy: 0.8735\n","Test acc: 0.874\n"]}]},{"cell_type":"code","source":["!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n","!tar -xf aclImdb_v1.tar.gz\n","!rm -r aclImdb/train/unsup"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Dc1k91HSHpS","executionInfo":{"status":"ok","timestamp":1670377950984,"user_tz":-480,"elapsed":17637,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}},"outputId":"75697a2b-6cfa-4e08-f08f-19641d1b2517"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100 80.2M  100 80.2M    0     0   9.8M      0  0:00:08  0:00:08 --:--:-- 16.5M\n"]}]},{"cell_type":"code","source":["from tensorflow.keras import layers\n","\n","max_length = 600\n","max_tokens = 20000\n","text_vectorization = layers.TextVectorization(\n","    max_tokens=max_tokens,\n","    output_mode=\"int\",\n","    output_sequence_length=max_length,\n",")\n","text_vectorization.adapt(text_only_train_ds)\n","\n","int_train_ds = train_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","int_val_ds = val_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","int_test_ds = test_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)"],"metadata":{"id":"lBFN8PMFTgwY","executionInfo":{"status":"ok","timestamp":1670378305328,"user_tz":-480,"elapsed":5230,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","class TransformerEncoder(layers.Layer):\n","    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n","        super().__init__(**kwargs)\n","        self.embed_dim = embed_dim\n","        self.dense_dim = dense_dim\n","        self.num_heads = num_heads\n","        self.attention = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embed_dim)\n","        self.dense_proj = keras.Sequential(\n","            [layers.Dense(dense_dim, activation=\"relu\"),\n","             layers.Dense(embed_dim),]\n","        )\n","        self.layernorm_1 = layers.LayerNormalization()\n","        self.layernorm_2 = layers.LayerNormalization()\n","\n","    def call(self, inputs, mask=None):\n","        if mask is not None:\n","            mask = mask[:, tf.newaxis, :]\n","        attention_output = self.attention(\n","            inputs, inputs, attention_mask=mask)\n","        proj_input = self.layernorm_1(inputs + attention_output)\n","        proj_output = self.dense_proj(proj_input)\n","        return self.layernorm_2(proj_input + proj_output)\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\n","            \"embed_dim\": self.embed_dim,\n","            \"num_heads\": self.num_heads,\n","            \"dense_dim\": self.dense_dim,\n","        })\n","        return config"],"metadata":{"id":"x26BTm0OTkiz","executionInfo":{"status":"ok","timestamp":1670378312915,"user_tz":-480,"elapsed":2,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["vocab_size = 20000\n","embed_dim = 256\n","num_heads = 2\n","dense_dim = 32\n","\n","inputs = keras.Input(shape=(None,), dtype=\"int64\")\n","x = layers.Embedding(vocab_size, embed_dim)(inputs)\n","x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n","x = layers.GlobalMaxPooling1D()(x)\n","x = layers.Dropout(0.5)(x)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model = keras.Model(inputs, outputs)\n","model.compile(optimizer=\"rmsprop\",\n","              loss=\"binary_crossentropy\",\n","              metrics=[\"accuracy\"])\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7jpae-E1Tn2B","executionInfo":{"status":"ok","timestamp":1670378337786,"user_tz":-480,"elapsed":988,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}},"outputId":"3dbf115b-f7e2-4a43-91d7-8f32c611b112"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_8\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_9 (InputLayer)        [(None, None)]            0         \n","                                                                 \n"," embedding_4 (Embedding)     (None, None, 256)         5120000   \n","                                                                 \n"," transformer_encoder (Transf  (None, None, 256)        543776    \n"," ormerEncoder)                                                   \n","                                                                 \n"," global_max_pooling1d (Globa  (None, 256)              0         \n"," lMaxPooling1D)                                                  \n","                                                                 \n"," dropout_7 (Dropout)         (None, 256)               0         \n","                                                                 \n"," dense_12 (Dense)            (None, 1)                 257       \n","                                                                 \n","=================================================================\n","Total params: 5,664,033\n","Trainable params: 5,664,033\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["callbacks = [\n","    keras.callbacks.ModelCheckpoint(\"transformer_encoder.keras\",\n","                                    save_best_only=True)\n","]\n","model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callbacks)\n","model = keras.models.load_model(\n","    \"transformer_encoder.keras\",\n","    custom_objects={\"TransformerEncoder\": TransformerEncoder})\n","print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1435NShMTsei","executionInfo":{"status":"ok","timestamp":1670379027112,"user_tz":-480,"elapsed":677305,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}},"outputId":"1304c68d-5fdc-447e-c0db-1ee90a90a5b8"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","625/625 [==============================] - 42s 63ms/step - loss: 0.4892 - accuracy: 0.7696 - val_loss: 0.3455 - val_accuracy: 0.8504\n","Epoch 2/10\n","625/625 [==============================] - 40s 64ms/step - loss: 0.3141 - accuracy: 0.8684 - val_loss: 0.2910 - val_accuracy: 0.8812\n","Epoch 3/10\n","625/625 [==============================] - 41s 65ms/step - loss: 0.2453 - accuracy: 0.9001 - val_loss: 0.2918 - val_accuracy: 0.8840\n","Epoch 4/10\n","625/625 [==============================] - 41s 66ms/step - loss: 0.1854 - accuracy: 0.9286 - val_loss: 0.3167 - val_accuracy: 0.8758\n","Epoch 5/10\n","625/625 [==============================] - 41s 66ms/step - loss: 0.1528 - accuracy: 0.9420 - val_loss: 0.3644 - val_accuracy: 0.8750\n","Epoch 6/10\n","625/625 [==============================] - 41s 66ms/step - loss: 0.1276 - accuracy: 0.9528 - val_loss: 0.4600 - val_accuracy: 0.8844\n","Epoch 7/10\n","625/625 [==============================] - 41s 65ms/step - loss: 0.1099 - accuracy: 0.9589 - val_loss: 0.4576 - val_accuracy: 0.8758\n","Epoch 8/10\n","625/625 [==============================] - 41s 65ms/step - loss: 0.0956 - accuracy: 0.9660 - val_loss: 0.5178 - val_accuracy: 0.8720\n","Epoch 9/10\n","625/625 [==============================] - 42s 66ms/step - loss: 0.0816 - accuracy: 0.9712 - val_loss: 0.4858 - val_accuracy: 0.8804\n","Epoch 10/10\n","625/625 [==============================] - 41s 66ms/step - loss: 0.0719 - accuracy: 0.9743 - val_loss: 0.5989 - val_accuracy: 0.8682\n","782/782 [==============================] - 18s 22ms/step - loss: 0.2839 - accuracy: 0.8809\n","Test acc: 0.881\n"]}]},{"cell_type":"code","source":["class PositionalEmbedding(layers.Layer):\n","    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n","        super().__init__(**kwargs)\n","        self.token_embeddings = layers.Embedding(\n","            input_dim=input_dim, output_dim=output_dim)\n","        self.position_embeddings = layers.Embedding(\n","            input_dim=sequence_length, output_dim=output_dim)\n","        self.sequence_length = sequence_length\n","        self.input_dim = input_dim\n","        self.output_dim = output_dim\n","\n","    def call(self, inputs):\n","        length = tf.shape(inputs)[-1]\n","        positions = tf.range(start=0, limit=length, delta=1)\n","        embedded_tokens = self.token_embeddings(inputs)\n","        embedded_positions = self.position_embeddings(positions)\n","        return embedded_tokens + embedded_positions\n","\n","    def compute_mask(self, inputs, mask=None):\n","        return tf.math.not_equal(inputs, 0)\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\n","            \"output_dim\": self.output_dim,\n","            \"sequence_length\": self.sequence_length,\n","            \"input_dim\": self.input_dim,\n","        })\n","        return config"],"metadata":{"id":"1QOpONI0WuPw","executionInfo":{"status":"ok","timestamp":1670379140161,"user_tz":-480,"elapsed":2,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["vocab_size = 20000\n","sequence_length = 600\n","embed_dim = 256\n","num_heads = 2\n","dense_dim = 32\n","\n","inputs = keras.Input(shape=(None,), dtype=\"int64\")\n","x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(inputs)\n","x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n","x = layers.GlobalMaxPooling1D()(x)\n","x = layers.Dropout(0.5)(x)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model = keras.Model(inputs, outputs)\n","model.compile(optimizer=\"rmsprop\",\n","              loss=\"binary_crossentropy\",\n","              metrics=[\"accuracy\"])\n","model.summary()\n","\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint(\"full_transformer_encoder.keras\",\n","                                    save_best_only=True)\n","]\n","model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callbacks)\n","model = keras.models.load_model(\n","    \"full_transformer_encoder.keras\",\n","    custom_objects={\"TransformerEncoder\": TransformerEncoder,\n","                    \"PositionalEmbedding\": PositionalEmbedding})\n","print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w5-7QKHmWw94","executionInfo":{"status":"ok","timestamp":1670379991520,"user_tz":-480,"elapsed":841941,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}},"outputId":"320c78ff-a7ce-42a4-eb23-2cc2a9f996f2"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_9\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_10 (InputLayer)       [(None, None)]            0         \n","                                                                 \n"," positional_embedding (Posit  (None, None, 256)        5273600   \n"," ionalEmbedding)                                                 \n","                                                                 \n"," transformer_encoder_1 (Tran  (None, None, 256)        543776    \n"," sformerEncoder)                                                 \n","                                                                 \n"," global_max_pooling1d_1 (Glo  (None, 256)              0         \n"," balMaxPooling1D)                                                \n","                                                                 \n"," dropout_8 (Dropout)         (None, 256)               0         \n","                                                                 \n"," dense_17 (Dense)            (None, 1)                 257       \n","                                                                 \n","=================================================================\n","Total params: 5,817,633\n","Trainable params: 5,817,633\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","625/625 [==============================] - 43s 66ms/step - loss: 0.4741 - accuracy: 0.7807 - val_loss: 0.2773 - val_accuracy: 0.8902\n","Epoch 2/10\n","625/625 [==============================] - 41s 66ms/step - loss: 0.2333 - accuracy: 0.9076 - val_loss: 0.3008 - val_accuracy: 0.8930\n","Epoch 3/10\n","625/625 [==============================] - 42s 66ms/step - loss: 0.1730 - accuracy: 0.9355 - val_loss: 0.2983 - val_accuracy: 0.8826\n","Epoch 4/10\n","625/625 [==============================] - 42s 66ms/step - loss: 0.1416 - accuracy: 0.9483 - val_loss: 0.3574 - val_accuracy: 0.8852\n","Epoch 5/10\n","625/625 [==============================] - 42s 67ms/step - loss: 0.1212 - accuracy: 0.9556 - val_loss: 0.3367 - val_accuracy: 0.8846\n","Epoch 6/10\n","625/625 [==============================] - 42s 67ms/step - loss: 0.1040 - accuracy: 0.9622 - val_loss: 0.3866 - val_accuracy: 0.8816\n","Epoch 7/10\n","625/625 [==============================] - 42s 67ms/step - loss: 0.0935 - accuracy: 0.9663 - val_loss: 0.4383 - val_accuracy: 0.8746\n","Epoch 8/10\n","625/625 [==============================] - 42s 67ms/step - loss: 0.0814 - accuracy: 0.9700 - val_loss: 0.4254 - val_accuracy: 0.8770\n","Epoch 9/10\n","625/625 [==============================] - 42s 67ms/step - loss: 0.0754 - accuracy: 0.9743 - val_loss: 0.4223 - val_accuracy: 0.8754\n","Epoch 10/10\n","625/625 [==============================] - 42s 67ms/step - loss: 0.0667 - accuracy: 0.9762 - val_loss: 0.5030 - val_accuracy: 0.8728\n","782/782 [==============================] - 19s 24ms/step - loss: 0.2753 - accuracy: 0.8885\n","Test acc: 0.889\n"]}]},{"cell_type":"code","source":["!wget http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n","!unzip -q spa-eng.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DTYvbGJJaCR-","executionInfo":{"status":"ok","timestamp":1670380011871,"user_tz":-480,"elapsed":905,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}},"outputId":"6dd0ef4f-281f-4178-f0fa-0d859fb98c6a"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-12-07 02:26:50--  http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.79.128, 108.177.119.128, 108.177.127.128, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.79.128|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2638744 (2.5M) [application/zip]\n","Saving to: ‘spa-eng.zip’\n","\n","spa-eng.zip         100%[===================>]   2.52M  --.-KB/s    in 0.007s  \n","\n","2022-12-07 02:26:51 (340 MB/s) - ‘spa-eng.zip’ saved [2638744/2638744]\n","\n"]}]},{"cell_type":"code","source":["text_file = \"spa-eng/spa.txt\"\n","with open(text_file) as f:\n","    lines = f.read().split(\"\\n\")[:-1]\n","text_pairs = []\n","for line in lines:\n","    english, spanish = line.split(\"\\t\")\n","    spanish = \"[start] \" + spanish + \" [end]\"\n","    text_pairs.append((english, spanish))"],"metadata":{"id":"Nm5ASDvxaEtA","executionInfo":{"status":"ok","timestamp":1670380021160,"user_tz":-480,"elapsed":873,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["import random\n","print(random.choice(text_pairs))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cjiCyxdiaHcp","executionInfo":{"status":"ok","timestamp":1670380027290,"user_tz":-480,"elapsed":357,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}},"outputId":"23363f4c-401e-44a9-824d-b0650fabbb3f"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["(\"We think that it's our duty to pay taxes.\", '[start] Creemos que es nuestro deber pagar los impuestos. [end]')\n"]}]},{"cell_type":"code","source":["import random\n","random.shuffle(text_pairs)\n","num_val_samples = int(0.15 * len(text_pairs))\n","num_train_samples = len(text_pairs) - 2 * num_val_samples\n","train_pairs = text_pairs[:num_train_samples]\n","val_pairs = text_pairs[num_train_samples:num_train_samples + num_val_samples]\n","test_pairs = text_pairs[num_train_samples + num_val_samples:]"],"metadata":{"id":"wnHRo8XCaJS_","executionInfo":{"status":"ok","timestamp":1670380035441,"user_tz":-480,"elapsed":341,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","import string\n","import re\n","\n","strip_chars = string.punctuation + \"¿\"\n","strip_chars = strip_chars.replace(\"[\", \"\")\n","strip_chars = strip_chars.replace(\"]\", \"\")\n","\n","def custom_standardization(input_string):\n","    lowercase = tf.strings.lower(input_string)\n","    return tf.strings.regex_replace(\n","        lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n","\n","vocab_size = 15000\n","sequence_length = 20\n","\n","source_vectorization = layers.TextVectorization(\n","    max_tokens=vocab_size,\n","    output_mode=\"int\",\n","    output_sequence_length=sequence_length,\n",")\n","target_vectorization = layers.TextVectorization(\n","    max_tokens=vocab_size,\n","    output_mode=\"int\",\n","    output_sequence_length=sequence_length + 1,\n","    standardize=custom_standardization,\n",")\n","train_english_texts = [pair[0] for pair in train_pairs]\n","train_spanish_texts = [pair[1] for pair in train_pairs]\n","source_vectorization.adapt(train_english_texts)\n","target_vectorization.adapt(train_spanish_texts)"],"metadata":{"id":"ydjDLZpHaNtq","executionInfo":{"status":"ok","timestamp":1670380069742,"user_tz":-480,"elapsed":10079,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["atch_size = 64\n","\n","def format_dataset(eng, spa):\n","    eng = source_vectorization(eng)\n","    spa = target_vectorization(spa)\n","    return ({\n","        \"english\": eng,\n","        \"spanish\": spa[:, :-1],\n","    }, spa[:, 1:])\n","\n","def make_dataset(pairs):\n","    eng_texts, spa_texts = zip(*pairs)\n","    eng_texts = list(eng_texts)\n","    spa_texts = list(spa_texts)\n","    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n","    dataset = dataset.batch(batch_size)\n","    dataset = dataset.map(format_dataset, num_parallel_calls=4)\n","    return dataset.shuffle(2048).prefetch(16).cache()\n","\n","train_ds = make_dataset(train_pairs)\n","val_ds = make_dataset(val_pairs)"],"metadata":{"id":"z02VYJkdaWa-","executionInfo":{"status":"ok","timestamp":1670380094482,"user_tz":-480,"elapsed":2137,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["for inputs, targets in train_ds.take(1):\n","    print(f\"inputs['english'].shape: {inputs['english'].shape}\")\n","    print(f\"inputs['spanish'].shape: {inputs['spanish'].shape}\")\n","    print(f\"targets.shape: {targets.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WQn9DblNaZho","executionInfo":{"status":"ok","timestamp":1670380102700,"user_tz":-480,"elapsed":1236,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}},"outputId":"3be17a19-c81e-4022-fc21-184482247972"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["inputs['english'].shape: (32, 20)\n","inputs['spanish'].shape: (32, 20)\n","targets.shape: (32, 20)\n"]}]},{"cell_type":"code","source":["from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","embed_dim = 256\n","latent_dim = 1024\n","\n","source = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n","x = layers.Embedding(vocab_size, embed_dim, mask_zero=True)(source)\n","encoded_source = layers.Bidirectional(\n","    layers.GRU(latent_dim), merge_mode=\"sum\")(x)"],"metadata":{"id":"gA0qJrgAaay5","executionInfo":{"status":"ok","timestamp":1670380115715,"user_tz":-480,"elapsed":3093,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["past_target = keras.Input(shape=(None,), dtype=\"int64\", name=\"spanish\")\n","x = layers.Embedding(vocab_size, embed_dim, mask_zero=True)(past_target)\n","decoder_gru = layers.GRU(latent_dim, return_sequences=True)\n","x = decoder_gru(x, initial_state=encoded_source)\n","x = layers.Dropout(0.5)(x)\n","target_next_step = layers.Dense(vocab_size, activation=\"softmax\")(x)\n","seq2seq_rnn = keras.Model([source, past_target], target_next_step)"],"metadata":{"id":"rvy87NQqakpv","executionInfo":{"status":"ok","timestamp":1670380155888,"user_tz":-480,"elapsed":1727,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","source":["seq2seq_rnn.compile(\n","    optimizer=\"rmsprop\",\n","    loss=\"sparse_categorical_crossentropy\",\n","    metrics=[\"accuracy\"])\n","seq2seq_rnn.fit(train_ds, epochs=5, validation_data=val_ds)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4edz2Tjxan8n","executionInfo":{"status":"ok","timestamp":1670381007640,"user_tz":-480,"elapsed":847117,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}},"outputId":"0b1e9718-7ca0-42c2-d45b-051fe2f6e721"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","2603/2603 [==============================] - 173s 61ms/step - loss: 1.6301 - accuracy: 0.4352 - val_loss: 1.3306 - val_accuracy: 0.5188\n","Epoch 2/5\n","2603/2603 [==============================] - 157s 60ms/step - loss: 1.3404 - accuracy: 0.5343 - val_loss: 1.1950 - val_accuracy: 0.5733\n","Epoch 3/5\n","2603/2603 [==============================] - 158s 61ms/step - loss: 1.2459 - accuracy: 0.5730 - val_loss: 1.1772 - val_accuracy: 0.5945\n","Epoch 4/5\n","2603/2603 [==============================] - 157s 60ms/step - loss: 1.2247 - accuracy: 0.5962 - val_loss: 1.1804 - val_accuracy: 0.6048\n","Epoch 5/5\n","2603/2603 [==============================] - 157s 60ms/step - loss: 1.2188 - accuracy: 0.6101 - val_loss: 1.1909 - val_accuracy: 0.6078\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f368ca2bdf0>"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":["import numpy as np\n","spa_vocab = target_vectorization.get_vocabulary()\n","spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n","max_decoded_sentence_length = 20\n","\n","def decode_sequence(input_sentence):\n","    tokenized_input_sentence = source_vectorization([input_sentence])\n","    decoded_sentence = \"[start]\"\n","    for i in range(max_decoded_sentence_length):\n","        tokenized_target_sentence = target_vectorization([decoded_sentence])\n","        next_token_predictions = seq2seq_rnn.predict(\n","            [tokenized_input_sentence, tokenized_target_sentence])\n","        sampled_token_index = np.argmax(next_token_predictions[0, i, :])\n","        sampled_token = spa_index_lookup[sampled_token_index]\n","        decoded_sentence += \" \" + sampled_token\n","        if sampled_token == \"[end]\":\n","            break\n","    return decoded_sentence\n","\n","test_eng_texts = [pair[0] for pair in test_pairs]\n","for _ in range(20):\n","    input_sentence = random.choice(test_eng_texts)\n","    print(\"-\")\n","    print(input_sentence)\n","    print(decode_sequence(input_sentence))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2-0xvHfne20j","executionInfo":{"status":"ok","timestamp":1670381287984,"user_tz":-480,"elapsed":14792,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}},"outputId":"3cb4d1f2-bd50-4061-8c86-025f7e3f9dc8"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["-\n","He was standing there with a vacant look.\n","1/1 [==============================] - 4s 4s/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 23ms/step\n","[start] Él estaba ahí con una [UNK] de [UNK] [end]\n","-\n","It's cloudy today. Why don't we go to the beach tomorrow?\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","[start] está [UNK] por qué no ir a la mañana a la mañana [end]\n","-\n","I'd like to meet some of your friends.\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","[start] me gustaría hablar de tus amigos [end]\n","-\n","There was widespread panic after the earthquake.\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","[start] había una [UNK] de las [UNK] [end]\n","-\n","He won by a small number of votes.\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","[start] Él ha hecho un de [UNK] de [UNK] [end]\n","-\n","Tom wants to show you something.\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","[start] tom quiere algo algo [end]\n","-\n","Do you want to sit somewhere else?\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","[start] quieres en más de lo que se [UNK] [end]\n","-\n","I'm being good to you this morning.\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","[start] estoy [UNK] de esta mañana [end]\n","-\n","Barack Obama is a Christian.\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","[start] [UNK] [UNK] es [UNK] [end]\n","-\n","One of the buttons has come off my coat.\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","[start] uno de los se ha [UNK] el de mi [UNK] [end]\n","-\n","I pretended that I was sleeping.\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","[start] me estaba que estaba en lo [UNK] [end]\n","-\n","I like that person.\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","[start] me gusta esa persona [end]\n","-\n","Cats are related to tigers.\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 20ms/step\n","[start] los niños son [UNK] de [UNK] [end]\n","-\n","I like to study French.\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","[start] me gusta estudiar francés [end]\n","-\n","I screamed.\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","[start] yo [UNK] [end]\n","-\n","He was petting the dog.\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 27ms/step\n","[start] Él estaba el perro [end]\n","-\n","I tried to learn the melody by heart.\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 21ms/step\n","[start] he hecho de la [UNK] de la me [UNK] [end]\n","-\n","Tom found the treasure at the bottom of the lake.\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","[start] tom el [UNK] el con el [UNK] del [UNK] [end]\n","-\n","I wish I had the time to stay and talk with you.\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 23ms/step\n","[start] ojalá el tiempo [UNK] y [UNK] a tiempo con [UNK] [end]\n","-\n","Tom came to visit us three days ago.\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 24ms/step\n","[start] tom vino a tres días hace tres años [end]\n"]}]},{"cell_type":"code","source":["class TransformerDecoder(layers.Layer):\n","    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n","        super().__init__(**kwargs)\n","        self.embed_dim = embed_dim\n","        self.dense_dim = dense_dim\n","        self.num_heads = num_heads\n","        self.attention_1 = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embed_dim)\n","        self.attention_2 = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embed_dim)\n","        self.dense_proj = keras.Sequential(\n","            [layers.Dense(dense_dim, activation=\"relu\"),\n","             layers.Dense(embed_dim),]\n","        )\n","        self.layernorm_1 = layers.LayerNormalization()\n","        self.layernorm_2 = layers.LayerNormalization()\n","        self.layernorm_3 = layers.LayerNormalization()\n","        self.supports_masking = True\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\n","            \"embed_dim\": self.embed_dim,\n","            \"num_heads\": self.num_heads,\n","            \"dense_dim\": self.dense_dim,\n","        })\n","        return config\n","\n","    def get_causal_attention_mask(self, inputs):\n","        input_shape = tf.shape(inputs)\n","        batch_size, sequence_length = input_shape[0], input_shape[1]\n","        i = tf.range(sequence_length)[:, tf.newaxis]\n","        j = tf.range(sequence_length)\n","        mask = tf.cast(i >= j, dtype=\"int32\")\n","        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n","        mult = tf.concat(\n","            [tf.expand_dims(batch_size, -1),\n","             tf.constant([1, 1], dtype=tf.int32)], axis=0)\n","        return tf.tile(mask, mult)\n","\n","    def call(self, inputs, encoder_outputs, mask=None):\n","        causal_mask = self.get_causal_attention_mask(inputs)\n","        if mask is not None:\n","            padding_mask = tf.cast(\n","                mask[:, tf.newaxis, :], dtype=\"int32\")\n","            padding_mask = tf.minimum(padding_mask, causal_mask)\n","        attention_output_1 = self.attention_1(\n","            query=inputs,\n","            value=inputs,\n","            key=inputs,\n","            attention_mask=causal_mask)\n","        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n","        attention_output_2 = self.attention_2(\n","            query=attention_output_1,\n","            value=encoder_outputs,\n","            key=encoder_outputs,\n","            attention_mask=padding_mask,\n","        )\n","        attention_output_2 = self.layernorm_2(\n","            attention_output_1 + attention_output_2)\n","        proj_output = self.dense_proj(attention_output_2)\n","        return self.layernorm_3(attention_output_2 + proj_output)"],"metadata":{"id":"YTeVR8xBfji7","executionInfo":{"status":"ok","timestamp":1670381462657,"user_tz":-480,"elapsed":539,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["class PositionalEmbedding(layers.Layer):\n","    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n","        super().__init__(**kwargs)\n","        self.token_embeddings = layers.Embedding(\n","            input_dim=input_dim, output_dim=output_dim)\n","        self.position_embeddings = layers.Embedding(\n","            input_dim=sequence_length, output_dim=output_dim)\n","        self.sequence_length = sequence_length\n","        self.input_dim = input_dim\n","        self.output_dim = output_dim\n","\n","    def call(self, inputs):\n","        length = tf.shape(inputs)[-1]\n","        positions = tf.range(start=0, limit=length, delta=1)\n","        embedded_tokens = self.token_embeddings(inputs)\n","        embedded_positions = self.position_embeddings(positions)\n","        return embedded_tokens + embedded_positions\n","\n","    def compute_mask(self, inputs, mask=None):\n","        return tf.math.not_equal(inputs, 0)\n","\n","    def get_config(self):\n","        config = super(PositionalEmbedding, self).get_config()\n","        config.update({\n","            \"output_dim\": self.output_dim,\n","            \"sequence_length\": self.sequence_length,\n","            \"input_dim\": self.input_dim,\n","        })\n","        return config"],"metadata":{"id":"Uz7zyKSGfnd0","executionInfo":{"status":"ok","timestamp":1670381470038,"user_tz":-480,"elapsed":386,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","source":["embed_dim = 256\n","dense_dim = 2048\n","num_heads = 8\n","\n","encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n","x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n","encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n","\n","decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"spanish\")\n","x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n","x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n","x = layers.Dropout(0.5)(x)\n","decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n","transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"],"metadata":{"id":"JlXHkprcfpTl","executionInfo":{"status":"ok","timestamp":1670381477971,"user_tz":-480,"elapsed":1598,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}}},"execution_count":60,"outputs":[]},{"cell_type":"code","source":["transformer.compile(\n","    optimizer=\"rmsprop\",\n","    loss=\"sparse_categorical_crossentropy\",\n","    metrics=[\"accuracy\"])\n","transformer.fit(train_ds, epochs=10, validation_data=val_ds)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ht3tXkNmfqss","executionInfo":{"status":"ok","timestamp":1670382627919,"user_tz":-480,"elapsed":1144128,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}},"outputId":"f1fda6cc-b86b-4deb-d302-29ca93fa343f"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","2603/2603 [==============================] - 110s 41ms/step - loss: 1.8656 - accuracy: 0.3599 - val_loss: 1.6197 - val_accuracy: 0.4120\n","Epoch 2/10\n","2603/2603 [==============================] - 107s 41ms/step - loss: 1.6468 - accuracy: 0.4241 - val_loss: 1.4983 - val_accuracy: 0.4550\n","Epoch 3/10\n","2603/2603 [==============================] - 107s 41ms/step - loss: 1.5361 - accuracy: 0.4600 - val_loss: 1.4324 - val_accuracy: 0.4861\n","Epoch 4/10\n","2603/2603 [==============================] - 107s 41ms/step - loss: 1.5124 - accuracy: 0.4844 - val_loss: 1.4463 - val_accuracy: 0.5033\n","Epoch 5/10\n","2603/2603 [==============================] - 107s 41ms/step - loss: 1.5250 - accuracy: 0.5001 - val_loss: 1.4543 - val_accuracy: 0.5106\n","Epoch 6/10\n","2603/2603 [==============================] - 108s 41ms/step - loss: 1.5226 - accuracy: 0.5099 - val_loss: 1.4591 - val_accuracy: 0.5133\n","Epoch 7/10\n","2603/2603 [==============================] - 107s 41ms/step - loss: 1.5193 - accuracy: 0.5157 - val_loss: 1.4497 - val_accuracy: 0.5203\n","Epoch 8/10\n","2603/2603 [==============================] - 108s 41ms/step - loss: 1.5096 - accuracy: 0.5241 - val_loss: 1.4381 - val_accuracy: 0.5271\n","Epoch 9/10\n","2603/2603 [==============================] - 107s 41ms/step - loss: 1.5003 - accuracy: 0.5300 - val_loss: 1.4439 - val_accuracy: 0.5279\n","Epoch 10/10\n","2603/2603 [==============================] - 107s 41ms/step - loss: 1.4956 - accuracy: 0.5333 - val_loss: 1.4265 - val_accuracy: 0.5350\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f3666e32400>"]},"metadata":{},"execution_count":61}]},{"cell_type":"code","source":["import numpy as np\n","spa_vocab = target_vectorization.get_vocabulary()\n","spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n","max_decoded_sentence_length = 20\n","\n","def decode_sequence(input_sentence):\n","    tokenized_input_sentence = source_vectorization([input_sentence])\n","    decoded_sentence = \"[start]\"\n","    for i in range(max_decoded_sentence_length):\n","        tokenized_target_sentence = target_vectorization(\n","            [decoded_sentence])[:, :-1]\n","        predictions = transformer(\n","            [tokenized_input_sentence, tokenized_target_sentence])\n","        sampled_token_index = np.argmax(predictions[0, i, :])\n","        sampled_token = spa_index_lookup[sampled_token_index]\n","        decoded_sentence += \" \" + sampled_token\n","        if sampled_token == \"[end]\":\n","            break\n","    return decoded_sentence\n","\n","test_eng_texts = [pair[0] for pair in test_pairs]\n","for _ in range(20):\n","    input_sentence = random.choice(test_eng_texts)\n","    print(\"-\")\n","    print(input_sentence)\n","    print(decode_sequence(input_sentence))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vXmm5E9DkorZ","executionInfo":{"status":"ok","timestamp":1670382806797,"user_tz":-480,"elapsed":5123,"user":{"displayName":"徐丞毅","userId":"16499387127989371531"}},"outputId":"5456c8ea-97ba-4ec5-d7f8-1454bbde4c47"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["-\n","I just feel so lost.\n","[start] solo me [UNK] [end]\n","-\n","I am afraid of bears.\n","[start] me tengo una [UNK] [end]\n","-\n","Nothing could be further from the truth.\n","[start] nada que más que la verdad [end]\n","-\n","Throw it to Tom.\n","[start] lo [UNK] [end]\n","-\n","He's not a very meticulous guy.\n","[start] Él no es muy buen gran gran gran gran gran gran gran gran gran gran gran gran gran gran buena\n","-\n","How's Tom going to do it?\n","[start] cómo va a hacer [end]\n","-\n","What time do you go to work?\n","[start] a qué hora hora [end]\n","-\n","Why don't you want to eat lunch with us?\n","[start] por qué no le le le gusta con él [end]\n","-\n","Tom did what he believed was right.\n","[start] tom lo que lo que era [end]\n","-\n","Tom is at the airport.\n","[start] tom está en el cuchillo [end]\n","-\n","This is the most beautiful sunset that I have ever seen.\n","[start] este es la [UNK] de [UNK] de visto a visto [end]\n","-\n","I know your father.\n","[start] sé tu padre [end]\n","-\n","Be polite to your parents.\n","[start] [UNK] de tus padres [end]\n","-\n","Why do you have two cars?\n","[start] por qué tiene dos dos [UNK] [end]\n","-\n","It doesn't seem to work.\n","[start] no parece que hacer [end]\n","-\n","You're a smart boy.\n","[start] eres un chico [end]\n","-\n","Monday is a difficult day.\n","[start] el lunes es un día [end]\n","-\n","I don't know.\n","[start] no sé [end]\n","-\n","I do not read books.\n","[start] no puedo las libros [end]\n","-\n","Tom wondered how long he'd have to wait for Mary.\n","[start] tom se dio que él que se que mary [end]\n"]}]}]}